{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HIBALL Winter School 2021.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aPO_JYvQFjmD"
      },
      "source": [
        "#<-- RUN THIS FIRST! \n",
        "\n",
        "#download project from github\n",
        "!git clone https://www.github.com/tfunck/hiball_winter_school_2021\n",
        "#change directory into the project directory\n",
        "%cd hiball_winter_school_2021\n",
        "\n",
        "# import libraries that will be used for code below\n",
        "from sklearn.cluster import SpectralClustering\n",
        "from sklearn.feature_extraction import image\n",
        "from skimage.filters import threshold_otsu, threshold_li, threshold_yen, threshold_mean, threshold_minimum, threshold_sauvola\n",
        "from sklearn.cluster import KMeans, DBSCAN,  AgglomerativeClustering\n",
        "from scipy.ndimage import label\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from skimage.transform import resize\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import imageio\n",
        "import os\n",
        "from glob import glob\n",
        "\n",
        "# define a function to save output images\n",
        "def save_output_images(img, seg, dirname, filename):\n",
        "    # Define output filenames\n",
        "    seg_fn = '{}/seg_{}'.format(dirname, os.path.basename(filename))\n",
        "    qc_fn = '{}/qc_{}'.format(dirname, os.path.basename(filename))\n",
        "\n",
        "    # Save qc image\n",
        "    plt.clf()\n",
        "    plt.subplot(2,1,1)\n",
        "    plt.imshow(img)\n",
        "    plt.subplot(2,1,2)\n",
        "    plt.imshow(seg)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(qc_fn)\n",
        "\n",
        "    # Save segemented image\n",
        "    imageio.imsave(seg_fn, seg)\n",
        "\n",
        "# Get list of images\n",
        "image_filenames = np.sort(glob('png/*.png'))\n",
        "\n",
        "# Create output directories if they don't exist\n",
        "for dir_name in ['threshold','kmeans','watershed','neuralnetwork']: os.makedirs(dir_name,exist_ok=True)\n",
        "\n",
        "# Load images\n",
        "images = [ imageio.imread(filename) for filename in image_filenames] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWRdbawOGgLp"
      },
      "source": [
        "#######################\n",
        "### 1. Thresholding ###\n",
        "#######################\n",
        "def threshold_segmentation(img, filename=None,  dirname='threshold'):\n",
        "    #create empty image array \n",
        "    seg = np.zeros_like(img)\n",
        "    #get threshold value\n",
        "    threshold_value = threshold_otsu(img)\n",
        "    #set all pixels that are >= otsu threshold value to 1 in seg image array \n",
        "    seg[ img >= threshold_value ] = 255\n",
        "\n",
        "    # Save qc and segemented image\n",
        "    if filename != None : save_output_images(img, seg, dirname, filename )\n",
        "\n",
        "    return seg\n",
        "\n",
        "### Segment with thresholding \n",
        "for filename, img in zip(image_filenames, images) :\n",
        "  print(filename)\n",
        "  threshold_segmentation(img, filename)\n",
        "\n",
        "### Excercise 1\n",
        "# Other thresholding techniques make different cuts in the image histogram\n",
        "# You can try them by changing \"threshold_otsu\" to: \"threshold_li\", \n",
        "# \"threshold_yen\", \"threshold_mean\", \"threshold_minimum\", \"threshold_sauvola\"."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djASAikEG134"
      },
      "source": [
        "##################\n",
        "### 2. K-Means ###\n",
        "##################\n",
        "def kmeans_segmentation(img,  filename=None, dirname='kmeans', save_output=True):\n",
        "    #Set initial values for 2 classes. One value is equal to 0, \n",
        "    #the other is equal to image max pixel intensities\n",
        "    init = np.array([0, img.max()]).reshape(-1,1)\n",
        "\n",
        "    # setup clustering model\n",
        "    model = KMeans(n_clusters=len(init), init=init)\n",
        "    \n",
        "    #img = resize(img, (64,64))\n",
        "    #model = AgglomerativeClustering(linkage='ward') \n",
        "\n",
        "    # run model on the data\n",
        "    seg = model.fit_predict(img.reshape(-1,1)).reshape(img.shape)\n",
        "\n",
        "    #Resize image \n",
        "    img = resize(img.astype(np.uint8), (256,256))\n",
        "    # Save qc and segemented image\n",
        "    if filename != None : save_output_images(img, seg, dirname, filename )\n",
        "\n",
        "    return seg\n",
        "\n",
        "# Segment with K-Means #\n",
        "for filename, img in zip(image_filenames, images) :\n",
        "  print(filename)\n",
        "  kmeans_segmentation(img, filename)\n",
        "  \n",
        "\n",
        "### Excercise 2\n",
        "#K-Means is only one of many possible clustering algorithms. You can try AgglomerativeClustering\n",
        "#in the kmeans_segmentation function. Just uncomment where the AgglomerativeClustering model is defined\n",
        "#and the line above it with \"resize\".\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS1d4G28G44o"
      },
      "source": [
        "####################\n",
        "### 3. Watershed ###\n",
        "####################\n",
        "def watershed_segmentation(img, filename=None, dirname='watershed', n_points=10, perc_max=90, save_output=True):\n",
        "    #define the voxels to use as seeds for the watershed algorithm\n",
        "    #in this case, we are finding which voxels are >= 90th percentile\n",
        "    #of image intensities\n",
        "    x, y = np.where(img >= np.percentile(img,[perc_max])[0])\n",
        "   \n",
        "    # create a list of the index values for the x and y vectors\n",
        "    i = np.arange(x.shape[0]).astype(int)\n",
        "   \n",
        "    # shuffle that list of index values around. this is not necessary\n",
        "    # but is just done to illustrate variability in segementation stemming\n",
        "    # from which seed points are selected\n",
        "    np.random.shuffle(i)\n",
        "\n",
        "    # create empty array\n",
        "    mask = np.zeros_like(img).astype(int)\n",
        "    # use the first n_points in the x and y vectors as seed points\n",
        "    mask[ x[i][0:n_points], y[i][0:n_points] ] = 1\n",
        "    # the \"label\" function will set a unique label for each seed point\n",
        "    mask, n = label(mask)\n",
        "\n",
        "    # Convert image from 2D greyscale image to a 2D 3-channel RGB image \n",
        "    img2 = np.rint(np.repeat(img[:, :, np.newaxis]*255, 3, axis=2)).astype(np.uint8) \n",
        "    \n",
        "    # Apply watershed segmentation on negative of image with seed points defined in mask\n",
        "    seg = cv2.watershed(-img2,mask)\n",
        "    \n",
        "    # Save qc and segemented image\n",
        "    if filename != None : save_output_images(img, seg, dirname, filename)\n",
        "\n",
        "    return seg\n",
        "\n",
        "# Segment with watershed method #\n",
        "for filename, img in zip(image_filenames, images) :\n",
        "  print(filename)\n",
        "  watershed_segmentation(img, filename, n_points=2000, perc_max=95)\n",
        "\n",
        "### Excercise 3\n",
        "# Watershed segmentation depends on specifying certain seed points.\n",
        "# At the moment, the code selects 10 random seed points in the top\n",
        "# 10 percentile of pixel intensities. You can try changing n_points\n",
        "# and perc_max. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGIh5Z8fjaOG"
      },
      "source": [
        "# Run this cell before using the neural network example.\n",
        "# Don't worry about understanding it unless you want to dive into the nitty gritty details.\n",
        "\n",
        "import numpy as np\n",
        "import imageio\n",
        "import os\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Input, Add, Multiply, Dense, MaxPooling3D, BatchNormalization, Reshape\n",
        "from tensorflow.keras.layers import Conv1D, Conv2D, Conv3D, Convolution2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import ZeroPadding3D, ZeroPadding2D, ZeroPadding1D, UpSampling2D, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.layers import LeakyReLU, MaxPooling2D, concatenate,Conv2DTranspose, Concatenate, ZeroPadding2D\n",
        "from tensorflow.keras.activations import relu\n",
        "from tensorflow.keras.callbacks import History, ModelCheckpoint\n",
        "from math import sqrt\n",
        "from glob import glob\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def make_unet(example_image):\n",
        "    image_dim  = imageio.imread(example_image).shape[0:2]\n",
        "    nlabels=2\n",
        "    \n",
        "    IN = Input(shape=(image_dim[0], image_dim[1],1))\n",
        "    \n",
        "    conv1 = Conv2D(8*2, (3, 3), activation='relu', padding='same')(IN)\n",
        "    conv1 = Conv2D(8*2, (3, 3), activation='relu', padding='same')(conv1)\n",
        "    conv1 = Dropout(0.1)(conv1)\n",
        "    pool1 = MaxPooling2D((2, 2),padding='same')(conv1) \n",
        " \n",
        "    conv2 = Convolution2D(16*2, (3,3), activation='relu', padding='same')(pool1)\n",
        "    conv2 = Convolution2D(16*2, (3,3), activation='relu', padding='same')(conv2)\n",
        "    conv2 = Dropout(0.1)(conv2)\n",
        "    pool2 = MaxPooling2D((2, 2),padding='same')(conv2) \n",
        "\n",
        "    conv3 = Convolution2D(32*2, (3,3), activation='relu', padding='same')(pool2)\n",
        "    conv3 = Convolution2D(32*2, (3,3), activation='relu', padding='same')(conv3)\n",
        "    conv3 = Dropout(0.1)(conv3)\n",
        "    pool3 = MaxPooling2D((2, 2),padding='same')(conv3) \n",
        "\n",
        "    conv4 = Convolution2D(64*2, (3,3), activation='relu', padding='same')(pool3) \n",
        "    conv4 = Convolution2D(64*2, (3,3), activation='relu', padding='same')(conv4) \n",
        "    conv4 = Dropout(0.1)(conv4)\n",
        "    pool4 = MaxPooling2D((2, 2),padding='same')(conv4) \n",
        " \n",
        "    conv5 = Convolution2D(128*2, (3,3), activation='relu', padding='same')(pool4) \n",
        "    conv5 = Convolution2D(128*2, (3,3), activation='relu', padding='same')(conv5) \n",
        "    conv5 = Dropout(0.1)(conv5)\n",
        "    \n",
        "    up5 = UpSampling2D((2, 2))(conv5)  \n",
        "    conc5 = Concatenate(axis=3)([up5, conv4]) \n",
        "    conv6 = Convolution2D(64*2, (3,3), activation='relu', padding='same')(conc5)\n",
        "    conv6 = Convolution2D(64*2, (3,3), activation='relu', padding='same')(conv6)\n",
        "    conv6 = Dropout(0.1)(conv6)\n",
        "\n",
        "    up6 = UpSampling2D(size=(2, 2))(conv6)\n",
        "    conc6 = Concatenate(axis=3)([up6, conv3])\n",
        "    conv7 = Convolution2D(32*2, (3,3), activation='relu', padding='same')(up6)\n",
        "    conv7 = Convolution2D(32*2, (3,3), activation='relu', padding='same')(conv7)\n",
        "    conv7 = Dropout(0.1)(conv7)\n",
        "\n",
        "    up7 = UpSampling2D(size=(2, 2))(conv7)\n",
        "    conc7 = Concatenate(axis=3)([up7, conv2])\n",
        "    conv8 = Convolution2D(16*2, (3,3), activation='relu', padding='same')(conc7) \n",
        "    conv8 = Convolution2D(16*2, (3,3), activation='relu', padding='same')(conv8)\n",
        "    conv8 = Dropout(0.1)(conv8)\n",
        "\n",
        "    #up8 = Conv2DTranspose( filters=16*2, kernel_size=(3,3), strides=(2, 2), padding='same')(conv8)\n",
        "    up8 = UpSampling2D(size=(2, 2))(conv8)\n",
        "    conc8 = Concatenate(axis=3)([up8, conv1])\n",
        "    conv9 = Convolution2D(8*2, (3,3), activation='relu', padding='same')(conc8) \n",
        "    conv9 = Convolution2D(8*2, (3,3), activation='relu', padding='same')(conv9)\n",
        "    conv9 = Dropout(0.1)(conv9)\n",
        "\n",
        "    conv10 = Convolution2D(nlabels, (1, 1), activation='softmax')(conv9)\n",
        "\n",
        "    model = keras.models.Model(inputs=[IN], outputs=conv10)\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "def generator(source_dir, label_dir, bounds, batch_size=10):\n",
        "    images =np.sort([ fn for fn in  glob(f'{source_dir}/*png') if not '_B' in fn ])\n",
        "    labels =np.sort([ fn for fn in  glob(f'{label_dir}/seg_*png') if not '_B' in fn ])\n",
        "    \n",
        "    #if len(images) != len(labels) :\n",
        "    #    print('Error: mismatch between number of images and number of labels. images:', len(images),'labels:', len(labels))\n",
        "\n",
        "    img_dim = imageio.imread(images[0]).shape[0:2]\n",
        "    i=int(bounds[0])\n",
        "    while True :\n",
        "        img_batch=np.zeros([batch_size, img_dim[0], img_dim[1], 1])\n",
        "        lbl_batch=np.zeros([batch_size, img_dim[0], img_dim[1], 1])\n",
        "        for ii in range(batch_size):\n",
        "            img_fn, lbl_fn = images[i], labels[i]\n",
        "            if os.path.basename(img_fn).split('_')[0] != os.path.basename(lbl_fn).split('_')[1] : \n",
        "                print('Error: source and label image dont match.', img_fn, lbl_fn)\n",
        "                exit(0)\n",
        "\n",
        "            if i + ii < bounds[1] :\n",
        "                i = int(i +  ii )\n",
        "            else : \n",
        "                i=int(bounds[0])\n",
        "\n",
        "            img_batch[ii,:,:,0] = imageio.imread(img_fn)\n",
        "            lbl_batch[ii,:,:,0] = imageio.imread(lbl_fn)\n",
        "\n",
        "        lbl_batch[ lbl_batch >0 ] = 1\n",
        "        lbl_batch = to_categorical(lbl_batch)\n",
        "\n",
        "        yield img_batch, lbl_batch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nSyxCtyHMJ4"
      },
      "source": [
        "#########################\n",
        "### 4. Neural Network ###\n",
        "#########################\n",
        "def neuralnetwork_segmentation(source_dir, label_dir, epochs=10):    \n",
        "    #load input images\n",
        "    images = glob(f'{source_dir}/*png')\n",
        "    \n",
        "    #create model based on unet architecture\n",
        "    model = make_unet(images[0])\n",
        "\n",
        "    #compile the model\n",
        "    model.compile(loss='binary_crossentropy', optimizer=keras.optimizers.Adam(0.0001), metrics=['categorical_accuracy'])\n",
        "\n",
        "    #get the number of images that are not of type 'B'. the 'B' images will be saved\n",
        "    #for testing the accuracy of the model\n",
        "    n=len([fn for fn in images if not '_B' in fn ])\n",
        "    #set number of of images that will be used to train the network to 70% of the total number of images\n",
        "    n_train = np.rint(n*0.7)\n",
        "    #set the number of images that will be used to validate the network to 30% of the total number of images\n",
        "    n_val = np.rint(n*0.3)\n",
        "    \n",
        "    #fit model\n",
        "    history = model.fit(\n",
        "            generator(source_dir,label_dir,(0,n_train),10), \n",
        "            validation_data=generator(source_dir,label_dir,(n_train,n_train+n_val)), \n",
        "            validation_steps=np.ceil(n_val/10), epochs=epochs,steps_per_epoch=np.ceil(n_train/n)) \n",
        "    \n",
        "    # for each image... \n",
        "    for i in range(len(images)) :\n",
        "        #set image filename\n",
        "        filename = images[i]\n",
        "        #load image\n",
        "        img = imageio.imread(filename)\n",
        "        #apply model to image\n",
        "        seg = model.predict(img.reshape(1,img.shape[0],img.shape[1],1) , batch_size = 1)\n",
        "        # model produces an array with two probability values for each pixel (prob that pixel is background / pixel is tissue)\n",
        "        # the \"argmax\" function returns 0 for pixels that are more likely to be background and 1 for pixels that a more likely to be tissue\n",
        "        seg = np.argmax(seg, axis=3).reshape(img.shape)\n",
        "        #save the output image\n",
        "        save_output_images(img, np.array(seg * 255).astype(np.uint8), 'neuralnetwork', filename)\n",
        "\n",
        "\n",
        "# Segment with Neural Network #\n",
        "neuralnetwork_segmentation('png', 'kmeans', epochs=10)\n",
        "### Excercise 4\n",
        "# Try and improve the performance of the model by changing the number of kernels, the size of the kernels, \n",
        "# the number of epochs, the dropout rate, etc. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMqAVatcHqoG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}